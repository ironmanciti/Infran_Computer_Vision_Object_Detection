{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e7c82e5",
   "metadata": {
    "id": "Rs3MiqMjSYla"
   },
   "source": [
    "**Connect Colab with Google Drive**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda13355",
   "metadata": {
    "id": "IR3zxDOYu_CQ"
   },
   "source": [
    "# **Detectron2: PyTorch 기반 모듈식 객체 감지 라이브러리**\n",
    "Detectron2는 Facebook 에서 만든 딥러닝 기반의 객체 탐지 및 분할 라이브러리입니다.  \n",
    "\n",
    "**1. Detectron2 설치**  \n",
    "- Google Colab 환경에서 Detectron2를 설치하고 설정합니다\n",
    "- 설치에 5 분 정도 소요\n",
    "\n",
    "**2. COCO 데이터셋 및 사전 학습된 모델 로드**\n",
    "\n",
    "**3. 사전 학습된 Faster R-CNN 모델로 객체 탐지**\n",
    "\n",
    "**4. 사전 학습된 Mask R-CNN을 이용한 객체 분할**\n",
    "\n",
    "**5. 사용자 정의 데이터셋(Balloon Dataset) 미세 조정(Fine-tuning)**\n",
    "\n",
    "**6. Detectron2를 사용한 모델 학습 (Fine-Tuning)**\n",
    "\n",
    "**7. 학습된 모델을 사용한 추론 및 평가**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71836b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2c83d52",
   "metadata": {
    "id": "e4e-U_ffbbco"
   },
   "source": [
    "필요한 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04687ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectron2의 로거(Logger)를 설정하는 코드\n",
    "# 로거(Logger)는 모델 실행 중 발생하는 정보(예: 학습 상태, 경고 메시지, 오류 등)를 기록하고 출력합니다.\n",
    "# import some common detectron2 utilities\n",
    "#https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md\n",
    "# Detectron2에서 제공하는 사전 학습된 모델(예: Faster R-CNN, Mask R-CNN)\n",
    "# 사전 학습된 모델을 사용해 이미지에서 추론(예측)을 수행하는 API\n",
    "# Detectron2 모델 설정(configuration) 관리\n",
    "# 객체 탐지 및 분할 결과를 시각화(예: 이미지 위에 바운딩 박스, 마스크, 클래스 정보 추가)\n",
    "# 데이터셋의 메타데이터(예: 클래스 이름, 색상 등)를 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e4ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cocodataset.org/#home\n",
    "# COCO 2017 train 데이터셋의 메타데이터를 불러옵니다.\n",
    "# 메타데이터에서 클래스 이름(thing_classes)을 가져옵니다.\n",
    "# 클래스의 개수와 이름을 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8496f2e4",
   "metadata": {
    "id": "uPylefZDfodq"
   },
   "source": [
    "- Local PC 에서 aeroplane image 찾아서 upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f544ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fe5b9f2",
   "metadata": {
    "id": "W0jhnjey3AAW"
   },
   "source": [
    "## 사전 학습된 Detectron2 모델을 사용한 객체 감지\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee5d07",
   "metadata": {
    "id": "PKnZ51MUCPBT"
   },
   "source": [
    "### Faster R-CNN\n",
    "- `faster_rcnn_R_101_FPN_3x`  사전학습 모델 사용\n",
    "```\n",
    "- R_101 : ResNet 101 Layer   \n",
    "- FPN :  Feature Pyramid Network - 객체 탐지에서 다양한 크기의 객체를 효과적으로 탐지하기 위해 사용되는 구조  \n",
    "- 3x: 기본 학습 스케줄의 3배(270,000 iteration, 약 36 epoch)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3327ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectron2에서 COCO 데이터셋 기반 사전 학습된 객체 탐지 모델 설정\n",
    "# 참조: https://github.com/facebookresearch/detectron2/tree/main/configs/COCO-Detection\n",
    "# Detectron2의 모델 설정 객체(cfg) 생성\n",
    "# 사전 학습된 Faster R-CNN 모델 구성 불러오기\n",
    "#  Faster R-CNN 모델의 사전 학습된 가중치 불러오기\n",
    "# 객체를 탐지할 최소 신뢰도(점수) 임계값을 0.5로 설정\n",
    "# predictor 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96dc98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습된 Faster R-CNN 모델(R_101_FPN_3x)을 사용하여 객체 탐지 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e430e8be",
   "metadata": {
    "id": "M6RXxkqqunZb"
   },
   "source": [
    "```\n",
    "{\n",
    "    '_image_size': (2592, 3888),  # 입력 이미지의 크기\n",
    "    '_fields': {\n",
    "        'pred_boxes': Boxes(tensor([...]))  # 예측된 바운딩 박스 좌표 (x1,y1,x2,y2)\n",
    "        'scores': tensor([...])  # 각 객체의 신뢰도 점수\n",
    "        'pred_classes': tensor([...])  # 각 객체의 클래스\n",
    "    }\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae6f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 확인. 모델 출력 형식에 대한 자세한 내용은 [Detectron2 공식 문서](https://detectron2.readthedocs.io/tutorials/models.html#model-output-format) 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15200892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectron2의 Visualizer를 사용하여 이미지 시각화\n",
    "# 예측 결과(outputs[\"instances\"])를 CPU로 변환한 뒤, Visualizer를 사용해 바운딩 박스, 마스크 등을 시각화\n",
    "# Matplotlib을 사용해 결과를 화면에 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbcc9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측된 클래스 레이블을 리스트로 변환\n",
    "# # 클래스 ID를 클래스 이름으로 변환\n",
    "# 예측된 클래스 이름을 출력합니다.\n",
    "# 예측된 바운딩 박스 좌표를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cbcb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO 데이터셋의 이미지 중 한개를 다운로드 (-q : 진행상황 표시 X, -O: 파일 이름 지정)\n",
    "# OpenCV를 사용하여 다운로드한 이미지를 읽어 NumPy 배열 형식으로 메모리에 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a06f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습된 Faster R-CNN 모델(R_101_FPN_3x)을 사용하여 객체 탐지 수행\n",
    "# Detectron2의 Visualizer를 사용하여 이미지를 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef4df80",
   "metadata": {
    "id": "9mF8MwBvNTFw"
   },
   "source": [
    "### Mask R-CNN을 이용한 객체 분할\n",
    "\n",
    "- Mask R-CNN (mask_rcnn_R_50_FPN_3x)을 사용  \n",
    "- 물체 탐지(Object Detection) + 인스턴스 분할(Instance Segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66970a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectron2의 설정 객체 생성\n",
    "# COCO 데이터셋에서 학습된 ResNet-50 백본 Mask R-CNN 모델 구성 파일 불러오기\n",
    "# 객체 검출 시 사용할 점수 임계값(Threshold) 설정\n",
    "# Detectron2 모델 저장소(Model Zoo)에서 사전 학습된 모델의 가중치 불러오기\n",
    "# DefaultPredictor 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff137b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bc0440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `Visualizer`를 사용하여 이미지에 예측 결과를 그립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd13b13",
   "metadata": {
    "id": "y9u2Po20k5wj"
   },
   "source": [
    "## 사용자 정의 데이터셋(Balloon Dataset) 미세 조정(Fine-tuning)\n",
    "\n",
    "COCO dataset 에는 baloon category 가 없으므로 COCO dataset으로 사전 학습된 Mask R-CNN 모델은 baloon 을 detect 하지 못함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c8ff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local PC 에서 baloons.jpg upload\n",
    "# 사전 학습된 Mask R-CNN 으로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115458b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectron2의 Visualizer를 사용하여 이미지를 시각화\n",
    "# 예측 결과(outputs[\"instances\"])를 CPU로 변환한 뒤, Visualizer를 사용해 바운딩 박스, 마스크 등을 시각화\n",
    "# Matplotlib을 사용해 결과를 화면에 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72a25b9",
   "metadata": {
    "id": "zWh6G5WyoLc6"
   },
   "source": [
    "## 사용자 정의 데이터세트에서 학습 (Fine Tuning)\n",
    "새 형식의 사용자 정의 데이터세트에서 기존 detectron2 모델을 학습하는 방법.\n",
    "\n",
    "풍선이라는 클래스가 하나뿐인 baloon segmentation dataset을 사용합니다. detectron2의 model zoo에서 제공되는 COCO 데이터세트에서 사전 학습된 기존 모델에서 baloon segmentation 모델을 학습합니다.\n",
    "\n",
    "COCO 데이터세트에는 \"baloon\" category가 없습니다. 몇 분 안에 이 새로운 클래스를 인식할 수 있을 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d900048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 다운로드/압축 해제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177d8ae0",
   "metadata": {
    "id": "6sPDAVkN-2gh"
   },
   "source": [
    "- VIA (VGG Image Annotator) 형식의 JSON 파일\n",
    "```\n",
    "{\n",
    "  \"fileref\": \"\",  // 파일 참조 (보통 빈 문자열로 유지됨)\n",
    "  \"size\": 668058,  // 이미지 파일 크기 (바이트 단위)\n",
    "  \"filename\": \"24631331976_defa3bb61f_k.jpg\",  // 이미지 파일 이름\n",
    "  \"base64_img_data\": \"\",  // Base64 인코딩된 이미지 데이터 (현재 없음)\n",
    "  \"file_attributes\": {},  // 이미지에 대한 추가 속성 (현재 없음)\n",
    "  \"regions\": {  // 이미지에서 객체(관심 영역, ROI)를 정의하는 부분\n",
    "    \"0\": {  // 첫 번째 객체 (여러 개의 영역이 있을 경우 \"1\", \"2\", ... 로 증가)\n",
    "      \"shape_attributes\": {  // 해당 영역의 도형(Shape) 속성\n",
    "        \"name\": \"polygon\",  // 다각형(Polygon) 형태의 영역\n",
    "        \"all_points_x\": [916, 913, 905, ...],  // 다각형 꼭짓점의 X 좌표 리스트\n",
    "        \"all_points_y\": [515, 583, 616, ...]  // 다각형 꼭짓점의 Y 좌표 리스트\n",
    "      },\n",
    "      \"region_attributes\": {}  // 특정 객체(영역)의 속성 (현재 없음)\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732f05b2",
   "metadata": {
    "id": "GIdnrNKNCQAP"
   },
   "source": [
    "- COCO 형식의 JSON 파일\n",
    "```\n",
    "{\n",
    "  \"info\": {  // 데이터셋 정보\n",
    "    \"description\": \"Custom Dataset\",  // 데이터셋 설명\n",
    "    \"version\": \"1.0\",  // 버전 정보\n",
    "    \"year\": 2025,  // 데이터셋 생성 연도\n",
    "    \"contributor\": \"User\",  // 기여자 정보\n",
    "    \"date_created\": \"2025-03-05\"  // 데이터셋 생성 날짜\n",
    "  },\n",
    "  \"licenses\": [  // 라이선스 정보\n",
    "    {\n",
    "      \"id\": 1,  \n",
    "      \"name\": \"Attribution 4.0 International (CC BY 4.0)\",  // 라이선스 이름\n",
    "      \"url\": \"https://creativecommons.org/licenses/by/4.0/\"  // 라이선스 URL\n",
    "    }\n",
    "  ],\n",
    "  \"images\": [  // 이미지 정보 목록\n",
    "    {\n",
    "      \"id\": 1,  // 이미지 ID (고유 식별자)\n",
    "      \"file_name\": \"24631331976_defa3bb61f_k.jpg\",  // 이미지 파일명\n",
    "      \"width\": 1024,  // 이미지 너비\n",
    "      \"height\": 768,  // 이미지 높이\n",
    "      \"license\": 1,  // 사용된 라이선스 ID\n",
    "      \"date_captured\": \"2025-03-05\"  // 이미지 캡처 날짜\n",
    "    }\n",
    "  ],\n",
    "  \"annotations\": [  // 주석(Annotation) 정보 목록\n",
    "    {\n",
    "      \"id\": 1,  // 객체 ID (고유 식별자)\n",
    "      \"image_id\": 1,  // 해당 객체가 속한 이미지 ID\n",
    "      \"category_id\": 1,  // 객체의 카테고리 ID (categories에서 정의됨)\n",
    "      \"segmentation\": [  // 다각형(Polygon) 형태의 객체 경계선 좌표[x1, y1, x2, y2, ..xn, yn]\n",
    "        [916, 515, 913, 583, 905, 616, 889, 656, 868, 696, 836, 737,\n",
    "         809, 753, 792, 767, 789, 777, 784, 785, 777, 785, 769, 778,\n",
    "         767, 768, 777, 766, 786, 760, 791, 755, 769, 755, 739, 743,\n",
    "         714, 728, 678, 702, 645, 670, 615, 629, 595, 588, 583, 539,\n",
    "         580, 500, 584, 458, 595, 425, 614, 394, 645, 360, 676, 342,\n",
    "         716, 329, 769, 331, 815, 347, 849, 371, 875, 398, 900, 442,\n",
    "         916, 504]\n",
    "      ],\n",
    "      \"area\": 50000,  // 객체의 영역(면적), 단위: 픽셀^2\n",
    "      \"bbox\": [580, 329, 336, 456],  // 바운딩 박스 좌표 (xmin, ymin, width, height)\n",
    "      \"iscrowd\": 0  // 객체가 개별적인지 여부 (0: 개별 객체, 1: 군집 객체)\n",
    "    }\n",
    "  ],\n",
    "  \"categories\": [  // 객체(카테고리) 정보 목록\n",
    "    {\n",
    "      \"id\": 1,  // 카테고리 ID (annotations의 category_id와 연결됨)\n",
    "      \"name\": \"object\",  // 객체 이름 (예: \"balloon\", \"car\" 등)\n",
    "      \"supercategory\": \"none\"  // 상위 카테고리 (없으면 \"none\")\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249025c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON 파일 읽기 및 파싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539db022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON 데이터 출력\n",
    "    # 각 이미지의 주석(region) 정보 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea10ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 세트가 COCO 형식인 경우 이 셀은 다음 세 줄로 대체될 수 있습니다.:\n",
    "# from detectron2.data.datasets import register_coco_instances\n",
    "# register_coco_instances(\"my_dataset_train\", {}, \"json_annotation_train.json\", \"path/to/image/dir\")\n",
    "# register_coco_instances(\"my_dataset_val\", {}, \"json_annotation_val.json\", \"path/to/image/dir\")\n",
    "# Detectron2의 BoxMode 모듈 가져오기 (바운딩 박스 모드 지정)\n",
    "# VIA 형식의 Annotation을 COCO 형식으로 변환하여 Detectron2에서 사용할 수 있는 딕셔너리 생성\n",
    "def get_balloon_dicts(img_dir):\n",
    "    # 이미지 디렉터리에서 JSON 파일 경로 지정\n",
    "        # 이미지 파일 경로와 크기 정보 저장\n",
    "        # 이미지 메타데이터 설정\n",
    "        # 이미지의 주석(객체 정보) 처리\n",
    "            # 객체 정보를 딕셔너리에 저장\n",
    "# 학습(train) 및 검증(val) 데이터셋 등록\n",
    "    # 데이터셋을 Detectron2에 등록\n",
    "    # 데이터셋의 메타데이터 설정\n",
    "# 학습 데이터셋의 메타데이터 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09110c2a",
   "metadata": {
    "id": "3a_MIZo4oscw"
   },
   "source": [
    "데이터 세트가 올바른 형식인지 확인하기 위해 학습 세트에서 무작위로 선택한 샘플의 주석을 시각화해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터셋에서 3개의 샘플을 무작위로 선택하여 시각화\n",
    "# \"balloon/train\" 경로의 데이터셋을 Detectron2 형식으로 변환하여 가져오기\n",
    "# 데이터셋에서 무작위로 3개의 샘플을 선택\n",
    "    # 이미지 파일을 읽어오기 (cv2.imread는 이미지를 BGR 형식으로 읽음)\n",
    "    # Detectron2의 Visualizer를 사용하여 이미지 시각화\n",
    "    # 데이터셋 정보(d)를 사용해 바운딩 박스, 세그멘테이션 등을 이미지 위에 그리기\n",
    "    # 시각화 결과를 Colab 환경에서 표시 (cv2_imshow는 Colab에서 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd826e34",
   "metadata": {
    "id": "iQKjm6KOo2kw"
   },
   "source": [
    "## Train\n",
    "\n",
    "이제 COCO 사전 훈련된 R50-FPN 마스크 R-CNN 모델을 풍선 데이터 세트에서 미세 조정해 보겠습니다. P100 GPU에서 300회 반복을 훈련하는 데 약 2분이 걸립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db33afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectron2에서 데이터 로딩 속도 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ae3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 시작 시간 기록\n",
    "# Detectron2의 기본 학습 트레이너(DefaultTrainer)를 불러옵니다.\n",
    "# Detectron2의 설정 객체 생성\n",
    "# 사전 학습된 Mask R-CNN 모델 구성 파일 로드\n",
    "# 학습 데이터셋 설정 (\"balloon_train\"으로 등록된 데이터셋 사용)\n",
    "# DataLoader의 워커 수 설정 (데이터 로드 병렬 처리, 워커 수는 CPU 코어 수와 관련)\n",
    "# 사전 학습된 모델 가중치 설정 (Detectron2 Model Zoo에서 가져옴)\n",
    "# 배치 크기 설정 (1번 학습 단계에서 처리할 이미지 수)\n",
    "# 학습률(Learning Rate) 설정\n",
    "# 학습 반복(iteration) 수 설정\n",
    "# 학습률 감소 단계 설정\n",
    "# RoI(Region of Interest) Head의 배치 크기 설정. 각 이미지에서 128개의 RoI sample을 학습에 사용\n",
    "# 모델의 클래스 수 설정\n",
    "# 출력 디렉터리 생성 (학습 결과 저장 디렉터리)\n",
    "# 기본 학습 트레이너(DefaultTrainer) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf9abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 종료 시간 기록\n",
    "# 실행 시간 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34b6bea",
   "metadata": {
    "id": "FaNLCf-1qSLm"
   },
   "source": [
    "## 훈련된 모델을 사용한 추론 및 평가\n",
    "이제 훈련된 모델로 baloon validation 데이터 세트에 대해  추론을 실행해 보겠습니다. 먼저 방금 훈련한 모델을 사용하여 predictor를 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3febfa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg 객체는 학습 시 사용했던 설정을 그대로 포함하고 있으며, 추론에 필요한 몇 가지 설정을 추가로 변경합니다.\n",
    "# 방금 학습한 모델의 최종 가중치 경로 설정\n",
    "# 추론 시 신뢰도 임계값 설정 (0.7 이상인 경우에만 예측 결과를 출력)\n",
    "# DefaultPredictor 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aba220",
   "metadata": {
    "id": "xEjxUCrRqXTr"
   },
   "source": [
    "여러 샘플을 무작위로 선택하여 예측 결과를 시각화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d0a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 데이터셋(\"balloon/val\")을 Detectron2 형식으로 가져옴\n",
    "# 검증 데이터셋에서 무작위로 3개의 샘플을 선택\n",
    "    # 이미지 파일 읽기 (OpenCV는 기본적으로 BGR 형식으로 이미지를 읽음)\n",
    "    # 학습된 모델을 사용하여 이미지에서 객체 추론\n",
    "    # Visualizer를 사용하여 추론 결과를 시각화\n",
    "    # 모델 추론 결과(outputs[\"instances\"])를 시각화\n",
    "    # Colab 환경에서 이미지를 표시 (cv2_imshow는 이미지를 BGR 형식으로 표시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed31479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델을 사용하여 이미지에서 객체 추론\n",
    "# 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델을 사용하여 이미지에서 객체 추론\n",
    "# Visualizer를 사용하여 추론 결과를 시각화\n",
    "# 모델 추론 결과(outputs[\"instances\"])를 시각화\n",
    "# Colab 환경에서 이미지를 표시 (cv2_imshow는 이미지를 BGR 형식으로 표시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2279d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
